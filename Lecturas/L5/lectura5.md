### Review: Combinación de Predicciones para Sistemas Recomendadores Precisos

El paper trata sobre la aplicación de técnicas de ensamble sobre sistemas recomendadores, es decir, de generar predicciones a partir de una combinación de los resultados obtenidos 
con cada modelo individual. Los modelos individuales utilizados son de filtrado colaborativo, utilizando las interacciones usuario-ítem para aprender. Entre estos modelos se encuentran los basados en KNN (K-Nearest Neighbors), SVD (Matrix Factorization), AFM (Asymmetric Factor Model), RBM (Restricted Boltzmann Machine) y GE (Global Effects). Se presentan distintos experimentos basados en ensambles, los que son evaluados utilizando la métrica del RMSE (Raíz del Error Cuadrático Medio). Las técnicas de ensamble probadas fueron:

* **LR (Linear Regression):** Infiere los pesos óptimos de la combinación lineal resolviendo el problema de los mínimos cuadrados.
* **BLR (Binned Linear Regression):** Divide el set de entrenamiento en distintos contenedores bajo algún criterio (tiempo, soporte, frecuencia). Se obtiene una combinación para cada uno de estos contenedores, eligiendo la correspondiente al contenedor que representa mejor al usuario y al ítem al momento de predecir.
* **NN (Neural Network):** Se entrena una red neuronal para obtener la predicción, recibiendo como entrada las predicciones de los modelos individuales.
* **BGBDT (Bagged Gradient Boosted Decision Tree):** Se aplican las técnicas de Bagging (entrenar distintas copias del modelo en sets de entrenamiento ligeramente distintos) y Boosting (entrenar modelos en cadena, cada uno aprendiendo una fracción de la predicción) al entrenar una serie de árboles de decisión.
* **KRR (Kernel Ridge Regression Blending):** Regresión basada en un kernel no lineal.
* **KNN (K-Nearest Neighbors Blending):** Se utilizan las K predicciones más cercanas.
* **Bagging + NN + GBDT + PR:** Se aplica la técnica de Bagging sobre 3 modelos (árboles de decisión, red neuronal, regresión polinomial), los que luego son combinados mediante regresión lineal simple.

Se observa que entre estos métodos de ensamble el mejor fue el de Bagging + NN + GBDT + PR, seguido de una NN por sí sola. Finalmente, se concluye que las técnicas de ensamble permiten generar un sistema recomendador preciso y robusto, capaz de competir con los mejores modelos individuales del estado del arte (aunque logra un rendimiento un poco menor).

En general el artículo me pareció interesante, aunque podría haber sido estructurado de mejor forma. Cada sección da la impresión de ser una enumeración de cada modelo y técnica utilizada, sin una clara separación entre los antecedentes y los modelos realmente probados en los experimentos. Aún así, el trabajo realizado fue bastante exhaustivo y se lograron probar muchas combinaciones de estas técnicas, indicando una buena aplicación del método científico. Quiero rescatar el hecho de que las redes neuronales son eficientes al momento de entrenar sobre datasets gigantescos, lo que justamente es la realidad en la que estos sistemas deberán desempeñarse al momento de ser aplicados sobre alguna plataforma. Esto indica que modelos basados en redes neuronales tiene un futuro prometedor al considerar el crecimiento acelerado de la información en el mundo.

Al analizar los resultados obtenidos en la competencia del Netflix Prize, se observa que las propuestas de ensamble logran un buen rendimiento, pero menor al de los mejores modelos individuales de la competencia. Una posible explicación de esto es que estos modelos de ensamble fueron entrenados y ajustados utilizando una pequeña fracción de los datos disponibles (set de probing), puesto que al depender de muchos modelos individuales el tiempo de entrenamiento y la memoria necesarios crecen demasiado.

Finalmente, creo que una forma de sobrellevar la limitante sobre estos sistemas de ensamble (tiempo y memoria limitados) a futuro corresponde a la paralelización al momento de entrenarlos, lo que quizás podría ser logrado gracias al hardware actual de las GPUs y TPUs que ha mejorado sustancialmente desde el año en el que se publicó este artículo (2010).
